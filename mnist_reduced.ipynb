{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "from scipy.misc import imshow\n",
    "from matplotlib import pyplot as plt\n",
    "from random import randint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f99b0aae3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "array = np.loadtxt(\"mnist.csv\", skiprows = 1, delimiter=',')\n",
    "plt.imshow(array[1,1:785].reshape(28,28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data separation\n",
    "# the separation may not be optimal since we favor \n",
    "#the training and test sets to fulfill the requirements\n",
    "nb_img = 42000\n",
    "nb_class = 10\n",
    "nb_train = int(nb_img * 0.7) #70% of data for training\n",
    "nb_test = int(nb_img * 0.25)\n",
    "nb_valid = nb_img - nb_train - nb_test\n",
    "id = randint(0, nb_img-1)\n",
    "train_set = array[id]\n",
    "idx = np.arange(nb_img)\n",
    "np.random.shuffle(idx)\n",
    "idx_train = idx[0:nb_train-1]\n",
    "idx_test = idx[nb_train+1:nb_train+nb_test]\n",
    "idx_valid = idx[nb_train+nb_test+1:]\n",
    "set_train = array[idx_train]\n",
    "set_test = array[idx_test]\n",
    "set_valid = array[idx_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = set_train[:,1:].reshape(set_train.shape[0], 28, 28, 1)\n",
    "X_train/=255\n",
    "X_test = set_test[:,1:].reshape(set_test.shape[0], 28, 28, 1)\n",
    "X_test/=255\n",
    "X_valid = set_valid[:,1:].reshape(set_valid.shape[0], 28, 28, 1)\n",
    "X_valid/=255\n",
    "Y_train = np_utils.to_categorical(set_train[:,0], nb_class)\n",
    "Y_test = np_utils.to_categorical(set_test[:,0], nb_class)\n",
    "Y_valid = np_utils.to_categorical(set_valid[:,0], nb_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0    1085\n",
      "1.0    1133\n",
      "2.0    1075\n",
      "3.0    1081\n",
      "4.0    1021\n",
      "5.0     925\n",
      "6.0    1017\n",
      "7.0    1116\n",
      "8.0    1014\n",
      "9.0    1032\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data=set_test)\n",
    "print(df.groupby([0]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 48)        480       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 48)        20784     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 10, 10, 96)        41568     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 96)          83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               196736    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 351,514\n",
      "Trainable params: 351,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nb_filters = 48\n",
    "nb_conv = 3\n",
    "nb_pool = 2\n",
    "images_rows = 28 #use origninal images\n",
    "images_cols = 28\n",
    "nb_categories = 10\n",
    "\n",
    "#VGG\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(nb_filters, (nb_conv, nb_conv), activation='relu', kernel_initializer='glorot_uniform', input_shape=(images_rows, images_cols, 1)))\n",
    "model.add(Conv2D(nb_filters, (nb_conv, nb_conv), activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "model.add(Conv2D(nb_filters*2, (nb_conv, nb_conv), activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Conv2D(nb_filters*2, (nb_conv, nb_conv), activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "    \n",
    "model.add(Dense(128, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(nb_categories, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29398 samples, validate on 2100 samples\n",
      "Epoch 1/5\n",
      "29398/29398 [==============================] - 101s 3ms/step - loss: 0.0073 - acc: 0.9979 - val_loss: 0.0491 - val_acc: 0.9895\n",
      "Epoch 2/5\n",
      "29398/29398 [==============================] - 104s 4ms/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0645 - val_acc: 0.9886\n",
      "Epoch 3/5\n",
      "29398/29398 [==============================] - 105s 4ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0715 - val_acc: 0.9876\n",
      "Epoch 4/5\n",
      "29398/29398 [==============================] - 104s 4ms/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.0637 - val_acc: 0.9886\n",
      "Epoch 5/5\n",
      "29398/29398 [==============================] - 104s 4ms/step - loss: 0.0045 - acc: 0.9988 - val_loss: 0.0528 - val_acc: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f997df7d128>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, Y_train, \n",
    "    epochs = 20, #only last final epochs are shown below\n",
    "    batch_size = 64,\n",
    "    shuffle = True,\n",
    "    verbose = 1,\n",
    "    callbacks = [EarlyStopping(monitor='loss', patience=5, mode='min')],\n",
    "    validation_data = (X_valid, Y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10499/10499 [==============================] - 12s 1ms/step\n",
      "Test accuracy:  0.992189732355\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR:  99.2095238095\n",
      "FPR:  0.790476190476\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict_classes(X_test)\n",
    "cm = confusion_matrix(set_test[:,0], y_predict)\n",
    "print(\"TPR: \", np.trace(cm)/nb_test*100)\n",
    "print(\"FPR: \", (nb_test-np.trace(cm))/nb_test*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the randomness of the data sets, the fitted model as well as the prediction accuracy may change at each run.\n",
    "The fitting can be improved by using a larger training dataset and/or deeper NN (maybe with more features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test, batch_size=64)\n",
    "\n",
    "y_pre = y_predict\n",
    "for i in range(predictions.shape[0]):\n",
    "    if np.amax(predictions[i,:]) < 0.9999999:\n",
    "        y_pre[i] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR(%):  99.9156118143\n",
      "FPR(%):  0.084388185654\n",
      "recall(%):  3.45930133678\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(set_test[:,0], y_pre)\n",
    "print(\"TPR(%): \", np.trace(cm)/np.sum(cm[:,1:])*100)\n",
    "print(\"FPR(%): \", (np.sum(cm[:,1:])-np.trace(cm))/np.sum(cm[:,1:])*100)\n",
    "print(\"recall(%): \", np.sum(cm[:,1])/nb_train*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is to use threshold(s) to guard from false positive. The overall thresholding is shown here. Similarly, this can be implemented at each class level to lower the recall rate due to the class discrepencies. However, the latter was not demonstrated here due to lack of time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
